{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29bca2f0-f656-4504-b846-b8ef41b37e7f",
   "metadata": {},
   "source": [
    "# Boston Home Price Forecasting Through PaddlePaddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7818491b-c483-48ef-a4c8-1d034c494646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "from paddle.nn import Linear\n",
    "import paddle.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "datafile = './housing.data'\n",
    "data = np.fromfile(datafile, sep = ' ')\n",
    "feature_names = ['CRIM', 'zn', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS',\n",
    "                'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "ratio = 0.8\n",
    "\n",
    "def load_data(data, feature_names, ratio):\n",
    "    feature_num = len(feature_names)\n",
    "\n",
    "    # reshape the data into [N, 14]\n",
    "    data = data.reshape([data.shape[0] // feature_num, feature_num])\n",
    "\n",
    "    # calculate the maximums, minimums, and averages for every column\n",
    "    maximums = data.max(axis = 0)\n",
    "    minimums = data.min(axis = 0)\n",
    "    avgs = data.sum(axis = 0) / data.shape[0]\n",
    "\n",
    "    print(data)\n",
    "    # normalize the data into [0, 1]\n",
    "    for i in range(feature_num):\n",
    "        data[:, i] = (data[:, i] - minimums[i]) / (maximums[i] - minimums[i])\n",
    "\n",
    "    # spilt the data into training data(80%) and testing data(20%)\n",
    "    offset = int(data.shape[0] * ratio)\n",
    "    train_data = data[: offset]\n",
    "    test_data = data[offset : -1]\n",
    "\n",
    "    return train_data, test_data, maximums, minimums, avgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9a4d81-81e3-442d-9d98-bb363b4938cb",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "\n",
    "Create a Python class to define your model's **initialization and forward function**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49c0ec97-fc29-4403-bcf3-4be793fc714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regressor(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(Regressor, self).__init__()\n",
    "\n",
    "        # define one fully connected layer, \n",
    "        # which has 13 input dimensions and 1 output dimensions\n",
    "        self.fc = Linear(in_features = 13, out_features = 1)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x = self.fc(inputs)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6f6d97-3887-4bc8-baea-caa636a8a66c",
   "metadata": {},
   "source": [
    "## Training Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1adcb254-268b-409e-bf6e-b30a0daf655a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.3200e-03 1.8000e+01 2.3100e+00 ... 3.9690e+02 4.9800e+00 2.4000e+01]\n",
      " [2.7310e-02 0.0000e+00 7.0700e+00 ... 3.9690e+02 9.1400e+00 2.1600e+01]\n",
      " [2.7290e-02 0.0000e+00 7.0700e+00 ... 3.9283e+02 4.0300e+00 3.4700e+01]\n",
      " ...\n",
      " [6.0760e-02 0.0000e+00 1.1930e+01 ... 3.9690e+02 5.6400e+00 2.3900e+01]\n",
      " [1.0959e-01 0.0000e+00 1.1930e+01 ... 3.9345e+02 6.4800e+00 2.2000e+01]\n",
      " [4.7410e-02 0.0000e+00 1.1930e+01 ... 3.9690e+02 7.8800e+00 1.1900e+01]]\n"
     ]
    }
   ],
   "source": [
    "# declare the predefined model\n",
    "model = Regressor()\n",
    "\n",
    "# open the model training on\n",
    "model.train()\n",
    "\n",
    "# load_data\n",
    "train_data, test_data, max_values, min_values, avg_values = \\\n",
    "            load_data(data, feature_names, ratio)\n",
    "\n",
    "# define optimization algorithm(SGD)\n",
    "# define the learning rate as 0.01\n",
    "opt = paddle.optimizer.SGD(learning_rate = 0.01, parameters = model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d31e7f-5fad-48be-9039-854ab20b858f",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eee1692e-0c0f-4e57-ba6d-f17ec14e6b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 / iter: 0, loss = 0.9022024869918823\n",
      "epoch: 0 / iter: 20, loss = 0.27136388421058655\n",
      "epoch: 0 / iter: 40, loss = 0.24334724247455597\n",
      "epoch: 1 / iter: 0, loss = 0.11687825620174408\n",
      "epoch: 1 / iter: 20, loss = 0.1603066474199295\n",
      "epoch: 1 / iter: 40, loss = 0.046303536742925644\n",
      "epoch: 2 / iter: 0, loss = 0.20476026833057404\n",
      "epoch: 2 / iter: 20, loss = 0.08621034771203995\n",
      "epoch: 2 / iter: 40, loss = 0.05824138969182968\n",
      "epoch: 3 / iter: 0, loss = 0.11593504995107651\n",
      "epoch: 3 / iter: 20, loss = 0.12232111394405365\n",
      "epoch: 3 / iter: 40, loss = 0.10337256640195847\n",
      "epoch: 4 / iter: 0, loss = 0.04896111041307449\n",
      "epoch: 4 / iter: 20, loss = 0.09840662032365799\n",
      "epoch: 4 / iter: 40, loss = 0.11095009744167328\n",
      "epoch: 5 / iter: 0, loss = 0.015612234361469746\n",
      "epoch: 5 / iter: 20, loss = 0.0559270866215229\n",
      "epoch: 5 / iter: 40, loss = 0.02309376560151577\n",
      "epoch: 6 / iter: 0, loss = 0.0636683851480484\n",
      "epoch: 6 / iter: 20, loss = 0.047666728496551514\n",
      "epoch: 6 / iter: 40, loss = 0.020763441920280457\n",
      "epoch: 7 / iter: 0, loss = 0.029086057096719742\n",
      "epoch: 7 / iter: 20, loss = 0.034519173204898834\n",
      "epoch: 7 / iter: 40, loss = 0.020985817536711693\n",
      "epoch: 8 / iter: 0, loss = 0.05518295615911484\n",
      "epoch: 8 / iter: 20, loss = 0.04337255284190178\n",
      "epoch: 8 / iter: 40, loss = 0.031039001420140266\n",
      "epoch: 9 / iter: 0, loss = 0.06451068073511124\n",
      "epoch: 9 / iter: 20, loss = 0.006137225776910782\n",
      "epoch: 9 / iter: 40, loss = 0.03466372191905975\n"
     ]
    }
   ],
   "source": [
    "# set epochs and batch size\n",
    "EPOCH_NUM = 10\n",
    "BATCH_SIZE = 10\n",
    "n = len(train_data)\n",
    "\n",
    "# \n",
    "for epoch_id in range(EPOCH_NUM):\n",
    "    # random arrange the training data in every epoch\n",
    "    np.random.shuffle(train_data)\n",
    "    # spilt the training data in batch size\n",
    "    mini_batches = [train_data[k : k + BATCH_SIZE] for k in range(0, n, BATCH_SIZE)]\n",
    "    for iter_id, mini_batch in enumerate(mini_batches):\n",
    "        x = mini_batch[:, : -1]\n",
    "        y = mini_batch[:, -1 :]\n",
    "        # convert numpy to tensor type\n",
    "        house_features = paddle.to_tensor(x, dtype=\"float32\")\n",
    "        prices = paddle.to_tensor(y, dtype=\"float32\")\n",
    "        \n",
    "        # 1. forward calculation\n",
    "        predicts = model(house_features)\n",
    "        # 2. loss\n",
    "        loss = F.square_error_cost(predicts, label = prices)\n",
    "        avg_loss = paddle.mean(loss)\n",
    "        if iter_id % 20 == 0:\n",
    "            print(\"epoch: {} / iter: {}, loss = {}\".format(epoch_id, iter_id, float(avg_loss)))\n",
    "        # 3. Backpropagation\n",
    "        avg_loss.backward()\n",
    "        # 4. update parameters\n",
    "        opt.step()\n",
    "        # 5. clear the gradient variables\n",
    "        opt.clear_grad()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c485f9-2a4a-4a59-a57c-30c128831718",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2bc900a6-4b8e-463f-a54e-b29e450c0a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save Successfully in ./LR_model.pdparms\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "paddle.save(model.state_dict(), 'LR_model.pdparams')\n",
    "print(\"save Successfully in ./LR_model.pdparms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a54d3e-29ee-489d-96ae-a5be9c942f91",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "363b7e9b-668c-4cf9-b0d5-1379dcefa50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_example(test_data):\n",
    "    idx = np.random.randint(0, test_data.shape[0])\n",
    "    one_data, label = test_data[idx, : -1], test_data[idx, -1]\n",
    "    # reshape the selected testing data\n",
    "    one_data = one_data.reshape([1, -1])\n",
    "\n",
    "    return one_data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d51dcdf1-0ad9-42f4-b931-614150954a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference result is 32.806671142578125, the corresponding label is 31.632806324110696\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model_dict = paddle.load('LR_model.pdparams')\n",
    "model.load_dict(model_dict)\n",
    "# start evaluation\n",
    "model.eval()\n",
    "\n",
    "one_data, label = load_example(test_data)\n",
    "# Varialbel mode in dynamic graph\n",
    "one_data = paddle.to_tensor(one_data, dtype=\"float32\")\n",
    "predict = model(one_data)\n",
    "\n",
    "# normalize the result\n",
    "predict = predict * (max_values[-1] - min_values[-1]) + avg_values[-1]\n",
    "label = label * (max_values[-1] - min_values[-1]) + avg_values[-1]\n",
    "\n",
    "print(\"Inference result is {}, the corresponding label is {}\".format(float(predict), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450b508f-f8e9-4f8f-92ed-425a5185d856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d456427-ade8-490d-8980-6e582bfc073d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
